{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from recbole.utils.case_study import full_sort_topk, full_sort_scores\n",
    "from recbole.quick_start import load_data_and_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Dec 18:03    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = dataset/emos\n",
      "checkpoint_dir = saved/\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = True\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 600\n",
      "train_batch_size = 8192\n",
      "learner = adam\n",
      "learning_rate = 0.0001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 8192\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 16\n",
      "wandb_project = new-ncf-rank\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "mf_embedding_size = 32\n",
      "mlp_embedding_size = 32\n",
      "mlp_hidden_size = [256, 128, 64, 32]\n",
      "dropout_prob = 0.1\n",
      "mf_train = True\n",
      "mlp_train = True\n",
      "use_pretrain = False\n",
      "mf_pretrain_path = None\n",
      "mlp_pretrain_path = None\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "12 Dec 18:03    INFO  emos\n",
      "The number of users: 55597\n",
      "Average actions of users: 66.91393265702568\n",
      "The number of items: 3423\n",
      "Average actions of items: 1087.1265341905319\n",
      "The number of inters: 3720147\n",
      "The sparsity of the dataset: 98.04520218801962%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "12 Dec 18:04    INFO  [Training]: train_batch_size = [8192] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "12 Dec 18:04    INFO  [Evaluation]: eval_batch_size = [8192] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n"
     ]
    }
   ],
   "source": [
    "config, model, dataset, train_data, valid_data, test_data = load_data_and_model(\n",
    "    model_file=\"saved/256_128_64_32__00001.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just for checking userID/ShiptoID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4089037</td>\n",
       "      <td>10137</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-08-25 00:18:19.675003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4374491</td>\n",
       "      <td>10137</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-08-25 00:18:19.676277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1839333</td>\n",
       "      <td>10137</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-08-25 00:18:19.677383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1759124</td>\n",
       "      <td>10137</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-08-25 00:18:19.677468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4236989</td>\n",
       "      <td>10137</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-08-25 00:18:19.677516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userID  itemID  rating                   timestamp\n",
       "0  4089037   10137       1  2023-08-25 00:18:19.675003\n",
       "1  4374491   10137       1  2023-08-25 00:18:19.676277\n",
       "2  1839333   10137       1  2023-08-25 00:18:19.677383\n",
       "3  1759124   10137       1  2023-08-25 00:18:19.677468\n",
       "4  4236989   10137       1  2023-08-25 00:18:19.677516"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dataset/emos/ncf_data_emos.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop Here for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2311])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uid_series = np.array([1, 2])  # internal user id series\n",
    "# or you can use dataset.token2id to transfer external user token to internal user id\n",
    "uid_series = dataset.token2id(dataset.uid_field, [\"4089037\"])\n",
    "uid_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_score, topk_iid_list = full_sort_topk(\n",
    "    uid_series, model, test_data, k=10, device=config[\"device\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9829, 0.9807, 0.9781, 0.9775, 0.9771, 0.9759, 0.9754, 0.9754, 0.9735,\n",
      "         0.9733]], device='cuda:0')\n",
      "[['11623' '12469' '11539' '11391' '15347' '13118' '13311' '14970' '11653'\n",
      "  '13564']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(topk_score)  # scores of top 10 items\n",
    "# print(topk_iid_list)  # internal id of top 10 items\n",
    "external_item_list = dataset.id2token(dataset.iid_field, topk_iid_list.cpu())\n",
    "print(external_item_list)  # external tokens of top 10 items\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# score = full_sort_scores(uid_series, model, test_data, device=config[\"device\"])\n",
    "# print(score)  # score of all items\n",
    "# print(\n",
    "#     score[0, dataset.token2id(dataset.iid_field, [\"10137\"])]\n",
    "# )  # score of item ['242', '302'] for user '196'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env-recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
